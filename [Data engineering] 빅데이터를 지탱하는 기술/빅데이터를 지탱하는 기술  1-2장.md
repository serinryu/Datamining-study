# 빅데이터를 지탱하는 기술

# 1장. 빅데이터 기초 지식

하지만, 현실적으로 항상 팀을 구성해 역할 분담할 수 있는 것은 아니다…..

## 빅데이터의 취급이 어려운 이유

1. 데이터 분석 방법을 모름
2. 데이터 처리에 수고와 시간이 걸림. → 이 책에서 다룰것. 데이터 분석 지식이 있더라도 효율적인 데이터 처리가 이뤄지지 않으면 할 수 있는 일은 적어짐. 어떻게 하면 효율적인 처리를 가능하게 할까? (데이터 엔지니어의 역할)

## 빅데이터 기술의 시작

인터넷의 보급으로 세계 곳곳에서 액세스 되는 시스템이 증가 → 기존 전통적인 관계형 데이터베이스(RDB)로는 취급할 수 없을 만큼 대량의 데이터 축적. 기존과 다른 구조에 대한 니즈 증가.

1. Hadoop : 다수의 컴퓨터에서 대량의 데이터를 처리하기 위한 시스템. 모여진 데이터를 나중에 집계하는 것이 목적.
2. NoSQL 데이터베이스 : RDB보다 고속의 읽기, 쓰기 가능 및 분산 처리에 효과적. 모여진 데이터를 집계하는 목적인 하둡과는 달리, 애플리케이션에서 온라인으로 접속하는 데이터베이스 
    1. 주요 NoSQL 데이터 : MongoDB, CouchDB, Riak, Cassandra, Redis

→ 이 둘을 조합해서 ‘NoSQL 데이터베이스에 기록하고 Haddop으로 분산처리하기'라는 흐름이 정착하게 됨. (분산 시스템에 의한 데이터 처리의 고속화) (2011년)

→ 분산 시스템의 비지니스 이용 개척 : 데이터 웨어하우스(데이터 분석을 기반) 제품이 사용되는 경우에도 하둡을 사용하는 경우가 증가. 가속도적으로 늘어나는 데이터 처리는 하둡에 맡기고, 비교적 작거나 중요한 데이터만을 데이터 웨어하우스에 넣는 식으로 사용을 구분하면서 데이터 웨어하우스의 부화를 줄일 수 있게 됨. 정리하자면, 하둡과 NoSQL 의 데이터베이스 분산 시스템 기술의 확립이 기존의 데이터 웨어 하우스를 보완, 대체하기 시작.

## 빅데이터 시대의 데이터 분석 기반

빅데이터 기술이 기존의 데이터 웨어하우스와 다른 점은 **다수의 분산 시스템**을 조합하여 확장성이 뛰어난 데이터 처리 구조를 만든다는 것. 정리하자면, ‘빅데이터 기술'이란 분산 시스템을 활용하면서 데이터를 순차적으로 가공해나가는 일련의 구조. (반대로, 스몰 데이터는 분산 시스템을 전혀 사용하지 않는 한 대의 컴퓨터로 데이터를 탐색하는 것. 해결하고자 하는 문제가 스몰 데이터 기술로 충분하다면, 그것을 사용하는 것이 시간을 훨씬 절약할 수 있다.)

- 데이터 파이프라인 : 일반적으로 차례대로 전달해나가는 데이터로 구성된 시스템 (데이터 수집 ~ 워크플로 관리). 어디서 데이터를 수집하여 무엇을 실현하고 싶은지에 따라 변화.
1. 데이터 수집 : 데이터 파이프라인의 시작점. 데이터는 여러 장소에서 발생하고, 서로 다른 기술로 데이터를 전송함. 데이터 전송(data transfer)방법에는 크게 1) 벌크(bulk)형, 2) 스트리밍(streaming)형. 
    1. 벌크형 : 이미 어딘가에 존재하는 데이터를 정리해 추출하는 방법. (데이터베이스와 파일 서버 등에서 정기적으로 데이터를 수집하는 데에 사용)
    2. 스트리밍형 : 차례차례로 생성되는 데이터를 끊임없이 계속해서 보내는 방법. (모바일 애플리케이션과 임베디드 장비 등에서 널리 데이터를 수집하는 데 사용) 
2. 스트림 처리, 배치 처리 :
    1. 스트림 처리(stream processing) : 스트리밍형으로 받은 데이터는 아무래도 **실시간**으로 처리하고 싶으니 스트림 처리. 
        1. 시계열 DB 와 같은 실시간 처리를 지향한 데이터베이스가 자주 사용됨. 스트림 처리 결과를 이 시계열 DB에 저장함으로써 현재 무슨 일이 일어나고 있는지 즉시 파악 가능
        2. 단, 장기적인 데이터 분석에는 적합하지 않을 수 있음. (지난 1년 간의 데이터 분석하려고 하면 데이터양 단번에 수만배로 증가..) 이럴땐 배치 처리 구조가 유리.
    2. 배치 처리(batch processing) : **대량**의 데이터를 저장하고 처리하는 데 적합한 분산 시스템. 즉, **어느 정도 정리된 데이터**를 효율적으로 가공하기 위한 구조. 
3. 분산 스토리지(distribute storage) : 수집된 데이터가 저장되는 곳. 여러 컴퓨터와 디스크로부터 구성된 storage system. 데이터를 저장하는 방법에는 몇 가지 방법이 있는데, 가장 대표적인 것이 ‘객체 스토리지(object storage)’로, 한 덩어리로 모인 데이터에 이름을 부여해 파일로 저장하는 방법. (예. 클라우드 서비스인 Amazon S3)
4. 분산 데이터 처리(distribute data processing) : 분산 스토리지에 저장된 데이터를 처리하는 데에는 ‘분산 데이터 처리'의 프레임워크가 필요함. 주 역할은, 나중에 분석하기 쉽도록 데이터를 가공해서 그 결과를 외부 데이터베이스에 저장하는 것. 
    1. 대부분 사람들은 데이터 집계하는 데 SQL 을 사용하는 데에 익숙하므로, 빅데이터를 SQL 로 집계하고 자 할때는 두 가지 방법이 있음. 
        1. 분산 스토리지 상의 데이터를 SQL 로 집계하기 위해 ‘쿼리 엔진(query engine)’을 도입하는 것. (예. Hive, Interactive query engine)
        2. 외부의 데이터웨어하우스 제품을 이용하는 것. → 이를 위해서는 분산 스토리지에서 추출한 데이터를 데이터 웨어하우스에 적합한 형식으로 변환해야 하고, 이 절차를 ETL 프로세스(Extract 데이터 추출 -transform 데이터 가공 -load 웨어하우스에 로드) 라고 한다. 
5. 워크플로 관리(workflow management) : 전체 데이터 파이프라인의 동작을 관리하기 위해 ‘워크플로 관리’ 기술 사용. 매일 정해진 시간에 배치 처리를 스케줄대로 실행하고, 오류가 발생하면 관리자에게 통지하는 목적으로 사용. 빅데이터 처리 시에는 크건 작건 시스템 장애가 발생하므로 오류 발생 시의 처리와 재실행을 위한 기능 제작은 필수임.

⇒ 빅데이터의 파이프 라인을 실현하려면 많은 기술과 소프트웨어가 사용된다. 전부 필수는 아니지만, 더 좋은 데이터 분석 환경을 구축하기 위해서는 각각의 특징들을 이해할 필요 있음.

⇒ 데이터 파이프라인의 큰 흐름은 변하지 않는다. 따라서, 빅데이터를 다루는 도구 선택의 경우 어떤 것을 선택해도 실제로 하는 일은 크게 다르지 않다. 1) 저장할 수 있는 데이터 용량에 제한이 없는지 2) 데이터를 효율적으로 추출할 수단이 있는지 이 2가지를 가지고 도구를 선택하면 됨.

## 데이터를 수집하는 목적

: 데이터를 수집한 후, 무엇을 실시할지는 “목적"에 따라 달라짐.


1. 데이터 검색이 목적이라면, 필요할 때 신속하게 검색할 수 있도록 해야함. 따라서, 시스템에는 실시간 데이터 처리나 검색 엔진을 활용해 키워드를 찾는 기능이 필요할 것. (예. 시스템 장애 시 그 원인 확인 위해 시스템 로그, 고객의 행동 이력 등을 확인할 때. 이 경우 데이터를 최대한 많이 취득해놔야겠지.) → 수동
2. 데이터 가공이 목적이라면, 목적이 명확하기 때문에 필요한 데이터를 계획적으로 모아 데이터 파이프 라인 설계해야 함. (예. 웹사이트에서 추천 상품 제안하거나, 센서 데이터의 비정상적인 상태 감시해 통보할 때.) → 데이터 가공에는 자동화가 필수적. 따라서, 워크플로 관리 도입해 꼼꼼히 테스트를 반복적으러 실행해 시스템 구축.
3. 데이터 시각화가 목적이라면, 확실한 해답은 없음. 임의의 분석 환경을 갖추고 여러번 데이터 집계를 반복함. 시각화를 고속화 하려면 데이터 마트로 필요함. (* 데이터 마트란? 수집한 로우 데이터를 그대로 보존하는 데이터 레이크에서, 분석용으로 일부를 추출한 데이터. 즉, 데이터 레이크가 데이터를 그대로 축적시키는 곳이라면, 데이터 마트에는 분석용으로 사용될 데이터를 따로 가공해 정리함. 그리고 그것을 BI 도구 등을 통해 액세스하고, 원하는 때에 원하는 정보를 얻을 수 있도록 함.)

## 데이터 분석

1. 확증적 데이터 분석(confirmatory data analysis) : 가설을 세우고 검증. 주로 통계학적인 모델링 (통계 분석, 머신러닝) → 이 분야는 이 책의 범위를 넘음. 다루지 않을 것. 이 책의 목적은 데이터 파이프라인을 자동화하는 부분까지임.
2. 탐색적 데이터 분석(exploratory data analysis) : 데이터 시각화한 것을 보고 그 의미를 인간이 읽어내는 것. → 이 책에서는 탐색적 데이터 분석을 위하여, 대화식으로 데이터를 집계하여 시각화하기 위한 환경을 만들 것.(파이썬, R과 같은 스크립트 언어를 사용한 데이터 처리, BI 도구를 사용한 데이터 디스커버리 등)

## 스몰데이터 탐색

스몰데이터 : 사내에서 작성된 엑셀(스프레드시트) 파일, 웹에서 다운로드한 CSV 파일 등…. 스몰 데이터 탐색은 분산 시스템을 전혀 사용하지 않는 한 대의 컴퓨터로 데이터를 탐색하는 것으로, 우리가 해결하고자 하는 문제가 스몰 데이터 기술로 충분하다면 그 방식으로 탐색하는 것이 효과적이므로 빅데이터 탐색 기술을 알기 전에 반드시 알고 있어야 함.

스프레드시트에 의한 보고서 작성은 그 한계점이 명확함. 

1. 보고서에 입력하는 숫자를 어디선가 계산해야 한다는 것. → 이를 위해 데이터 웨어하우스 등장. 여기서 실행되는 것이 배치 처리이고 이것은 자동화될 수 있음.
2. 상세한 내역을 조사하는 것이 어려움. → 이를 위해 BI 도구 사용. (예. Tableaus Public, Quick Sencse, Microsoft Power BI, Google data studio) BI 도구는 고속의 집계 엔진을 내장하고 있어 수백만 레코드 정도의 스몰 데이터라면 순식간에 그래프 그려주기 때문에, 애드 혹 분석(ad hoc analysis)에서 대화형으로 데이터를 시각화하고 싶을 때 특히 편리함. 

*애드 혹 분석이란? 자동화를 생각하지 않고 수작업으로 데이터를 집계하여 분석하는 것. 일회성 데이터 분석이라는 의미. SQL 쿼리를 직접 작성해서 실행하거나 스프레드시트 에서 그래프를 만드는 것 까지 포함해 모든 수작업이 애드 혹 분석에 포함됨.

*BI 도구를 위한 테이블을 처음부터 설계하기 보다는 우선 수동으로 입력하는 것이 쉬울 것. 이후, 자주 업데이트 되는 데이터와 다수의 사람에게 공유되는 데이터 등 중요성이 높은 것은 차례로 자동화해 나간다. 자동화하려는 경우에는 데이터 마트를 만든다. 

# 2. 빅데이터의 탐색 (시각화 시스템 위주)

데이터 집계 → 데이터 마트 → 시각화 

데이터 집계와 시각화 사이에 있는 것이 데이터 마트. 데이터 마트가 너무 작을 경우, 피벗 테이블과 BI 도구를 사용해 대화적인 데이터를 검색한다면 정보 부족으로 곤란한 상황이 될 것이고, 데이터 마트가 너무 거대할 경우 좋은 시각화를 할 수 없게 된다. 즉, trade off 관계에 있으며, 결국 데이터 마트의 크기에 따라 시각화 시스템 구성이 결정됨.

## 데이터베이스 지연 줄이고 고속화하기

데이터양이 증가함에 따라 집계에 걸리는 시간은 증가함. 데이터 집계에 너무 많은 시간이 소요되면, 작업 효율은 매우 악화됨. 데이터베이스의 지연은 어떻게 줄일까? 대량의 데이터를 신속하게 집계하기 위해, 미리 데이터를 **집계 효율이 높은 데이터 베이스로 변환**하는 것이 필요하다.

대화식으로 데이터를 시각화하고 그 내용을 알기 위해서는 ‘초 단위로의 고속 집계’가 요구된다. 그것을 예상해서 시스템을 다음과 같이 마련해야 함.

- 3계층의 데이터 집계 시스템 : 원 데이터를 대량의 데이터를 처리할 수 있는 **데이터 레이크와 데이터 웨어하우스**에 저장함.(수분~수시간 단위의 데이터 집계) 거기서 원하는 데이터를 추출하여 **데이터 마트**를 구축하고 여기에서는 초 단위의 응답을 얻을 수 있게 한다.(수초 단위의 크로스 집계)

→ 데이터 웨어하우스나 데이터 레이크는 대량의 데이터 처리를 위해 주로 ‘처리량(일정 시간안에 처리할 수 있는 데이터양)’을 중시하는 설계로 되어 있는 한편, 데이터 마트에 요구 되는 것은 **‘지연 시간의 단축’**


- 데이터 처리의 지연이 적은 데이터 마트 작성 : 데이터 마트를 만들 때에는 가급적 지연이 적은(latency 가 적은) 데이터베이스가 있어야 하는데, 크게 두 가지 선택이 있다.
1. 데이터가 작은 경우: 모든 데이터를 메모리에 올리면 됨. 
    1. 만약 한 레코드 크기가 500바이트이면 천만 레코드의 경우 5GB. 이 정도면 MySQL 등의 일반적인 RDB가 데이터 마트에 적합함. RDB 는 지연이 적고 많은 수의 클라이언트가 동시 접속해도 성능이 나빠지지 않으므로 많은 사용자가 이용하는 실제 운영 환경의 데이터 마트로 특히 우수함. 그러나, RDB는 메모리가 부족하면 성능이 급격히 저하되므로 수억 레코드를 초과하는 데이터 집계에는 적합하지 않음.
2. 데이터가 많은 경우 : ‘MPP 데이터베이스' 등을 이용하여 ‘열 지향’ 으로 데이터가 보관되도록 하는 것이 좋음. (열 지향(column-oriented) 스토리지에 의한 고속화)
    1. 고속화를 위해 사용되는 기법이 ‘압축’과 ‘분산'. 데이터를 가능한 한 작게 압축하고 그것을 여러 디스크에 분산함으로써 데이터의 로드에 따른 지연을 줄일 수 있음. 분산된 데이터를 읽어들이려면 멀티코어를 활용하면서 디스크 I/O를 병렬 처리하는 것이 효과적. 이러한 아키텍처를 MPP (massive parallel processing: 대규모 병렬 처리) 라고 함.
    2. 일반적인 업무 시스템에서 사용되는 데이터베이스(Oracle Database, MySQL 과 같은 일반적인 RDB 포함) 은 “레코드 단위"의 읽고쓰기에 최적화 되어 있는 ‘행 지향 데이터베이스(row-oriented)’ 이지만, 데이터 분석에 사용되는 데이터베이스는 “칼럼 단위”의 집계에 최적화되어 있는 ‘열 지향 데이터베이스(column-oriented database)’임.  (예. Teradata, Amazon Redshint) → 열 지향 데이터베이스는 데이터 압축 효율이 우수.
    3. MPP 데이터베이스를 사용하면 병렬화에 의한 쿼리 고속화가 가능함. MPP 데이터베이스에서는 여러 디스크에서 분산된 데이터가 서로 다른 CPU 코어에 의해 집계되어(CPU 코어 수에 비례하여 고속화됨) 부분적인 쿼리 실행이 이뤄지고, 그 결과들은 한 곳에 모여 최종적인 결과가 출력됨. 이러한 처리는 가능한 한 동시에 병렬로 실행됨. → ‘MPP 데이터베이스'와 ‘대화형 쿼리 엔진' 중 어느 쪽을 선택할지는 때에 따라 다르다. 시스템 안정성은 MPP 데이터 베이스, 하둡과의 궁합은 대화형 쿼리 엔진. 
    
    <aside>
    📌 - 행 지향 데이터 베이스 : 테이블의 각 행이 디스크 상에서 일련의 데이터로 쓰여짐. 새로운 레코드를 추가할 때는 끝부분에 추가되므로 고속으로 쓰기가 가능하고, 데이터 검색을 고속화하기 위해 인덱스(index) 를 만듬.  → 한편, 데이터 분석에서는 어떤 칼럼이 사용되는지 미리 알 수 없으므로 인덱스가 거의 도움되지 않음. 인덱스에 의지하지 않는 고속화 기술이 필요.
    
    - 열 지향 데이터베이스 : 칼럼별로 데이터를 보관해두므로, 필요한 칼럼만을 로드하여 디스크 I/O 를 줄임. 데이터를 집계하는 데는 고속이지만, 데이터 저장 시에는 시간이 걸림. → 데이터 분석에서는 종종 일부 칼럼만이 집계 대상(예. 상품 종류에 따른 가격을 알고 싶다면 상품의 공장명 까지는 필요없음) 
    
    </aside>
    
    ⇒ 정리하면, 열 지향 스토리지와 MPP 개념을 결합함으로써 데이터의 집계가 크게 고속화된다. 
    
    +) 컴퓨터의 성능 향상에 따라 데이터의 집계 속도는 해마다 빨라지고 있음. 이러한 이유로 데이터 마트를 만들지 않아도 되는 경우가 늘어나고 있음. 매번 모든 데이터를 데이터 웨어하우스에서 새롭게 집계하면 되기 때문. 그러나, 현실적으로는 크고 작은 성능상의 이유로 시스템의 부하를 낮출 필요가 있음.