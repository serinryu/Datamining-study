# 4장. 빅데이터의 축적

## 데이터 저장

빅데이터는 대부분의 경우 확장성이 높은 ‘분산 스토리지(distributed storage)’에 저장된다. 분산 형의 데이터베이스가 이용되는 경우도 있지만, 우선 기본이 되는 것은 대량으로 파일을 저장하기 위한 ‘객체 스토리지(object storage)’다. (Hadoop 이라면 ‘HDFS’, 클라우드 서비스라면 ‘Amazon S3’)

+) 객체 스토리지에서의 파일 읽고 쓰기는 네트워크를 거쳐서 실행한다. 또한, 다수의 컴퓨터를 사용하여 파일을 여러 디스크에 복사함으로써 데이터의 중복화 및 부하 분산을 실현한다. 즉, 파일 읽고 쓰기를 다수의 하드웨어에 복사해 분산함으로써 데이터의 양이 늘어나도 성능이 떨어지는 일이 없도록 고안되었다. 그러나, 오히려 데이터양이 100바이트의 작은 양이라면 오히려 비효율적인데, 이것은 데이터양에 비해 통신 오버헤드가 너무 크기 때문. 

## 데이터 수집

수집한 데이터를 가공하여 집계 효율이 좋은 분산 스토리지를 만드는 일련의 프로세스를 ‘데이터 수집(data ingestion)’이라고 한다. 

빅데이터로 자주 다루는 데이터는 ‘시계열 데이터' (시간과 함께 생성되는 데이터). 이것을 수시로 객체 스토리지에 기록하면 대량의 작은 파일이 생성되어 시간이 지남에 따라 성능을 저하시키는 요인이 된다. 따라서, 작은 데이터는 적당히 모아서 하나의 큰 파일로 만듦으로써 효율을 높이는데 도움이 된다.

⇒ 너무 작은 데이터는 모아서 하나의 큰 파일로 (분산 스토리지에) 저장한다.

반대로, 파일이 지나치게 클 경우 네트워크 전송에  시간이 걸려 오류 발생률이 높아진다. 이럴 경우, 한 번에 처리하는 것이 아니라 적당히 나눔으로써 문제 발생을 줄일 수 있다.

⇒ 너무 큰 데이터는 분할해서 기록한다.
