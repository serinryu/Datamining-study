# â­ï¸ The Steps in Data Mining

![á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-06-09 á„‹á…©á„’á…® 3 09 25](https://user-images.githubusercontent.com/74564995/172776681-c852fc05-3461-4c11-9bb8-73044ee6e780.png)

## [Preprocessing, Prelimiary process Step]

### 1. Develop an understanding of the purpose of the data mining project

- How will the stakeholder use the results? Who will be affected by the results? Will the analysis be a one-shot effort or an ongoing procedure?

### 2. Obtain the dataset to be used in the analysis: Sampling

- Sampling technique(ex. simple random sampling, stratified sampling, cluster sampling, multistage sampling...)
- If the event we are interested in classifying is rare, sampling may yield too few interesting cases to effectively train a model. So, we need appropriate number  of respondents or success cases to train a model. â†’ solution : Oversample the rare events to obtain a balanced training set and adjust results to equal the number of each case. 

### 3. Explore, clean, and preprocess the data

- This step involves verifying that the data are in reasonable condition. How should missing data be handled? Are the values in a reasonable range, given what you would expect for each variable? Are there obvious outliers? 
- Outlier : 
  - Values that lie far away from the bulk of the data are called outliers.
- Missing Values(NaN) : 
  - An alternative to omitting records with missing values is to replace the missing value with an imputed value, based on the other values for that variable across all records.

### 4. Reduce the data dimension, if necessary

- Dimension reduction can involve operations such as eliminating unneeded variables, transforming variables and creating new variables. Make sure that you know what each variable means and whether it is sensible to include it in the model.
- Dimension reduction approaches: 
  - (1) incorporating domain knowledge to remove or combine categories, 
  - (2) using data summaries to detect information overlap between variables (and remove or combine redundant variables or categories), 
  - (3) using data conversion techniques such as converting categorical variables into numerical variables, 
  - (4) employing automated reduction techniques, such as principal components analysis (PCA), where a new set of variables (which are weighted averages of the original variables) is created.

### 5. Determine the data mining task (classification, prediction, clustering, etc.)

- This involves translating the general question or problem of Step 1 into a more specific data mining question.


## [Modeling Step]

### 6. Partition the data (for supervised tasks)

> ğŸ“Œ Training data â†’ Validation data â†’ Test data â†’ NEW DATA

- Training ë°ì´í„°(í›ˆë ¨ë°ì´í„°)ì™€ Input ë°ì´í„°ê°€ 'ë‹¬ë¼ì ¸ë„' ë˜‘ê°™ì€ ì„±ëŠ¥ìœ¼ë¡œ ì¶œë ¥ë˜ì–´ì•¼ í•œë‹¤(ì¼ë°˜í™”). ì¦‰, Training ë°ì´í„°ê°€ ì¤‘ìš”í•œ ê²ƒì´ ì•„ë‹ˆë¼ ê·¸ ë°ì´í„°ë¥¼ ê°€ì§€ê³  Test ë°ì´í„°ì— ì ìš©í•´ë´¤ì„ ë•Œ ë¹„ìŠ·í•œ ì„±ê³¼ê°€ ë‚˜ì˜¤ëŠ” ê²ƒì´ ì¤‘ìš”í•¨!! â†’ ì¼ë°˜í™”ê°€ ì œëŒ€ë¡œ ë˜ì§€ ì•Šì„ ë•ŒëŠ” ë‘ ê°€ì§€ ë¬¸ì œê°€ ë°œìƒí•œë‹¤. ê³¼ëŒ€ì í•©overfitting(ë„ˆë¬´ ë³µì¡í•´ì„œ ë¬¸ì œ ë°œìƒ) í˜¹ì€ ê³¼ì†Œì í•©underfitting(ë„ˆë¬´ ë‹¨ìˆœí•´ ë°ì´í„°ì— ë‚´ì¬ëœ êµ¬ì¡°ë¥¼ í•™ìŠµí•˜ì§€ ëª»í• ë•Œ ë°œìƒ). ë”°ë¼ì„œ ì¼ë°˜í™”ë¥¼ ìœ„í•´ì„œëŠ” ë°ì´í„° ê°„ì˜ í¼í¬ë¨¼ìŠ¤ë¥¼ ì£¼ì˜ê¹Šê²Œ ì˜ ë´ì•¼í•˜ê³ , ì´ë¥¼ ìœ„í•´ training data, validation data, test data 3ê°œë¡œ ë°ì´í„°ì…‹ì„ ë¶„ë¦¬í•œë‹¤.
- If the task is supervised (classification or prediction), randomly partition the dataset into three parts: training, validation, and test datasets.

### 7. Choose the data mining techniques to be used (regression, neural nets, hierarchical clustering, and so on).

### 8. Use algorithms to perform the task:

- This is typically an iterative processâ€”trying multiple variants, and often using multiple variants of the same algorithm (choosing different variables or settings within the algorithm). Where appropriate, feedback from the algorithmâ€™s performance on validation data is used to refine the settings.

### 9. Interpret the results of the algorithms: Evaluate results and compare models, best model ê²°ì •

- This involves making a choice as to the best algorithm to deploy, and where possible, testing the final choice on the test data to get an idea as to how well it will perform. (Recall that each algorithm may also be tested on the validation data for tuning purposes; in this way, the validation data become a part of the fitting process and are likely to underestimate the error in the deployment of the model that is finally chosen.)

### 10. Deploy the model

- This step involves integrating the model into operational systems and running it on real records to produce decisions or actions. For example, the model might be applied to a purchased list of possible customers, and the action might be â€œinclude in the mailing if the predicted amount of purchase is > $10.â€ A key step here is â€œscoringâ€ the new records, or using the chosen model to predict the outcome value (â€œscoreâ€) for each new record.
